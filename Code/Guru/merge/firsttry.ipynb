{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/Sem5/DL/DL-Project/Code/Guru/merge/images/NEFT.jpg: 1216x896 15 boxInputs, 18 lineInputs, 1 signature, 81.4ms\n",
      "Speed: 8.9ms preprocess, 81.4ms inference, 11.3ms postprocess per image at shape (1, 3, 1216, 896)\n",
      "Results saved to \u001b[1mruns/detect/predict8\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load your model\n",
    "model = YOLO(\"./models/best-071024-3.pt\")\n",
    "# Make a prediction\n",
    "results = model.predict(source='./images/NEFT.jpg', save=True, conf=0.25, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"bbox\": [\n",
      "            1593.97314453125,\n",
      "            289.24444580078125,\n",
      "            2230.648193359375,\n",
      "            359.25933837890625\n",
      "        ],\n",
      "        \"confidence\": 0.9829572439193726,\n",
      "        \"class_id\": 3\n",
      "    },\n",
      "    {\n",
      "        \"bbox\": [\n",
      "            420.12554931640625,\n",
      "            1166.6220703125,\n",
      "            1178.8392333984375,\n",
      "            1235.150146484375\n",
      "        ],\n",
      "        \"confidence\": 0.9820379018783569,\n",
      "        \"class_id\": 3\n",
      "    },\n",
      "    {\n",
      "        \"bbox\": [\n",
      "            949.0014038085938,\n",
      "            399.6697692871094,\n",
      "            1390.4024658203125,\n",
      "            466.61163330078125\n",
      "        ],\n",
      "        \"confidence\": 0.9602988362312317,\n",
      "        \"class_id\": 5\n",
      "    },\n",
      "    {\n",
      "        \"bbox\": [\n",
      "            414.6068115234375,\n",
      "            1519.8336181640625,\n",
      "            1134.2467041015625,\n",
      "            1588.5987548828125\n",
      "        ],\n",
      "        \"confidence\": 0.9386115670204163,\n",
      "        \"class_id\": 3\n",
      "    },\n",
      "    {\n",
      "        \"bbox\": [\n",
      "            422.8742370605469,\n",
      "            1584.0404052734375,\n",
      "            2206.197509765625,\n",
      "            1657.9854736328125\n",
      "        ],\n",
      "        \"confidence\": 0.932572603225708,\n",
      "        \"class_id\": 3\n",
      "    },\n",
      "    {\n",
      "        \"bbox\": [\n",
      "            381.5419616699219,\n",
      "            1035.319091796875,\n",
      "            2225.16015625,\n",
      "            1101.0794677734375\n",
      "        ],\n",
      "        \"confidence\": 0.9311312437057495,\n",
      "        \"class_id\": 3\n",
      "    },\n",
      "    {\n",
      "        \"bbox\": [\n",
      "            365.3584899902344,\n",
      "            1096.140625,\n",
      "            2223.21240234375,\n",
      "            1171.301025390625\n",
      "        ],\n",
      "        \"confidence\": 0.9282705187797546,\n",
      "        \"class_id\": 3\n",
      "    },\n",
      "    {\n",
      "        \"bbox\": [\n",
      "            409.030517578125,\n",
      "            894.9376220703125,\n",
      "            882.1332397460938,\n",
      "            961.2113647460938\n",
      "        ],\n",
      "        \"confidence\": 0.9241487383842468,\n",
      "        \"class_id\": 3\n",
      "    },\n",
      "    {\n",
      "        \"bbox\": [\n",
      "            1670.002197265625,\n",
      "            225.89674377441406,\n",
      "            2227.400390625,\n",
      "            291.3052673339844\n",
      "        ],\n",
      "        \"confidence\": 0.9205964207649231,\n",
      "        \"class_id\": 3\n",
      "    },\n",
      "    {\n",
      "        \"bbox\": [\n",
      "            1724.73779296875,\n",
      "            404.53228759765625,\n",
      "            2215.58984375,\n",
      "            470.87322998046875\n",
      "        ],\n",
      "        \"confidence\": 0.9115860462188721,\n",
      "        \"class_id\": 5\n",
      "    },\n",
      "    {\n",
      "        \"bbox\": [\n",
      "            197.1354217529297,\n",
      "            3036.83203125,\n",
      "            709.1875610351562,\n",
      "            3112.447509765625\n",
      "        ],\n",
      "        \"confidence\": 0.9059165716171265,\n",
      "        \"class_id\": 5\n",
      "    },\n",
      "    {\n",
      "        \"bbox\": [\n",
      "            393.51202392578125,\n",
      "            1317.58154296875,\n",
      "            2215.59228515625,\n",
      "            1382.29638671875\n",
      "        ],\n",
      "        \"confidence\": 0.9011550545692444,\n",
      "        \"class_id\": 3\n",
      "    },\n",
      "    {\n",
      "        \"bbox\": [\n",
      "            406.67315673828125,\n",
      "            813.69873046875,\n",
      "            1435.4547119140625,\n",
      "            885.0274658203125\n",
      "        ],\n",
      "        \"confidence\": 0.8982698321342468,\n",
      "        \"class_id\": 3\n",
      "    },\n",
      "    {\n",
      "        \"bbox\": [\n",
      "            451.3697509765625,\n",
      "            1388.7840576171875,\n",
      "            1494.2947998046875,\n",
      "            1451.8131103515625\n",
      "        ],\n",
      "        \"confidence\": 0.8601061701774597,\n",
      "        \"class_id\": 3\n",
      "    },\n",
      "    {\n",
      "        \"bbox\": [\n",
      "            1217.9228515625,\n",
      "            2981.22607421875,\n",
      "            1656.4635009765625,\n",
      "            3047.614990234375\n",
      "        ],\n",
      "        \"confidence\": 0.849214494228363,\n",
      "        \"class_id\": 5\n",
      "    },\n",
      "    {\n",
      "        \"bbox\": [\n",
      "            1716.401123046875,\n",
      "            901.2025146484375,\n",
      "            2241.360107421875,\n",
      "            967.1167602539062\n",
      "        ],\n",
      "        \"confidence\": 0.820713996887207,\n",
      "        \"class_id\": 3\n",
      "    },\n",
      "    {\n",
      "        \"bbox\": [\n",
      "            413.8533935546875,\n",
      "            2647.548583984375,\n",
      "            1185.1522216796875,\n",
      "            2729.90966796875\n",
      "        ],\n",
      "        \"confidence\": 0.7173575162887573,\n",
      "        \"class_id\": 5\n",
      "    },\n",
      "    {\n",
      "        \"bbox\": [\n",
      "            786.3914184570312,\n",
      "            2743.672119140625,\n",
      "            1172.441162109375,\n",
      "            2803.694091796875\n",
      "        ],\n",
      "        \"confidence\": 0.7120798826217651,\n",
      "        \"class_id\": 5\n",
      "    },\n",
      "    {\n",
      "        \"bbox\": [\n",
      "            1097.0555419921875,\n",
      "            2907.142333984375,\n",
      "            1655.2935791015625,\n",
      "            2975.077392578125\n",
      "        ],\n",
      "        \"confidence\": 0.6880553364753723,\n",
      "        \"class_id\": 5\n",
      "    },\n",
      "    {\n",
      "        \"bbox\": [\n",
      "            267.7754211425781,\n",
      "            2539.532958984375,\n",
      "            582.5812377929688,\n",
      "            2574.8291015625\n",
      "        ],\n",
      "        \"confidence\": 0.6454209089279175,\n",
      "        \"class_id\": 5\n",
      "    },\n",
      "    {\n",
      "        \"bbox\": [\n",
      "            417.6875,\n",
      "            1452.99755859375,\n",
      "            1519.2542724609375,\n",
      "            1516.9202880859375\n",
      "        ],\n",
      "        \"confidence\": 0.5434542298316956,\n",
      "        \"class_id\": 3\n",
      "    },\n",
      "    {\n",
      "        \"bbox\": [\n",
      "            273.7950134277344,\n",
      "            2314.67138671875,\n",
      "            768.41845703125,\n",
      "            2453.129150390625\n",
      "        ],\n",
      "        \"confidence\": 0.49560195207595825,\n",
      "        \"class_id\": 6\n",
      "    },\n",
      "    {\n",
      "        \"bbox\": [\n",
      "            389.20025634765625,\n",
      "            1452.507568359375,\n",
      "            2225.7783203125,\n",
      "            1515.2821044921875\n",
      "        ],\n",
      "        \"confidence\": 0.4832031726837158,\n",
      "        \"class_id\": 3\n",
      "    },\n",
      "    {\n",
      "        \"bbox\": [\n",
      "            110.06771087646484,\n",
      "            2807.637451171875,\n",
      "            1352.1903076171875,\n",
      "            2883.468505859375\n",
      "        ],\n",
      "        \"confidence\": 0.4709509313106537,\n",
      "        \"class_id\": 5\n",
      "    },\n",
      "    {\n",
      "        \"bbox\": [\n",
      "            798.9102172851562,\n",
      "            276.738037109375,\n",
      "            1429.3111572265625,\n",
      "            334.5543212890625\n",
      "        ],\n",
      "        \"confidence\": 0.46591615676879883,\n",
      "        \"class_id\": 5\n",
      "    },\n",
      "    {\n",
      "        \"bbox\": [\n",
      "            173.96875,\n",
      "            2539.8154296875,\n",
      "            574.755126953125,\n",
      "            2571.83056640625\n",
      "        ],\n",
      "        \"confidence\": 0.4250747263431549,\n",
      "        \"class_id\": 5\n",
      "    },\n",
      "    {\n",
      "        \"bbox\": [\n",
      "            407.6407165527344,\n",
      "            2650.32763671875,\n",
      "            955.0184936523438,\n",
      "            2722.54248046875\n",
      "        ],\n",
      "        \"confidence\": 0.3572002053260803,\n",
      "        \"class_id\": 5\n",
      "    },\n",
      "    {\n",
      "        \"bbox\": [\n",
      "            103.8008804321289,\n",
      "            2448.6904296875,\n",
      "            378.4656982421875,\n",
      "            2495.3623046875\n",
      "        ],\n",
      "        \"confidence\": 0.3458773195743561,\n",
      "        \"class_id\": 5\n",
      "    },\n",
      "    {\n",
      "        \"bbox\": [\n",
      "            272.39141845703125,\n",
      "            2359.940185546875,\n",
      "            760.0474243164062,\n",
      "            2440.2998046875\n",
      "        ],\n",
      "        \"confidence\": 0.34310856461524963,\n",
      "        \"class_id\": 5\n",
      "    },\n",
      "    {\n",
      "        \"bbox\": [\n",
      "            1088.667236328125,\n",
      "            1875.708984375,\n",
      "            1404.3350830078125,\n",
      "            1909.3011474609375\n",
      "        ],\n",
      "        \"confidence\": 0.3200066387653351,\n",
      "        \"class_id\": 5\n",
      "    },\n",
      "    {\n",
      "        \"bbox\": [\n",
      "            165.86248779296875,\n",
      "            2534.974853515625,\n",
      "            426.4002380371094,\n",
      "            2581.54541015625\n",
      "        ],\n",
      "        \"confidence\": 0.29575762152671814,\n",
      "        \"class_id\": 5\n",
      "    },\n",
      "    {\n",
      "        \"bbox\": [\n",
      "            428.3322448730469,\n",
      "            960.4512329101562,\n",
      "            1622.3983154296875,\n",
      "            1030.90966796875\n",
      "        ],\n",
      "        \"confidence\": 0.28683528304100037,\n",
      "        \"class_id\": 3\n",
      "    },\n",
      "    {\n",
      "        \"bbox\": [\n",
      "            1027.9454345703125,\n",
      "            280.5272521972656,\n",
      "            1407.5584716796875,\n",
      "            328.51971435546875\n",
      "        ],\n",
      "        \"confidence\": 0.27043184638023376,\n",
      "        \"class_id\": 5\n",
      "    },\n",
      "    {\n",
      "        \"bbox\": [\n",
      "            811.5648803710938,\n",
      "            2454.144775390625,\n",
      "            1100.0496826171875,\n",
      "            2500.979736328125\n",
      "        ],\n",
      "        \"confidence\": 0.26481708884239197,\n",
      "        \"class_id\": 5\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Extract results\n",
    "detections = []\n",
    "for result in results:\n",
    "    for detection in result.boxes:  # Access the detected boxes\n",
    "        x1, y1, x2, y2 = detection.xyxy[0]  # Bounding box coordinates\n",
    "        confidence = detection.conf[0]      # Confidence score\n",
    "        class_id = int(detection.cls[0])    # Class ID\n",
    "        \n",
    "        detections.append({\n",
    "            'bbox': [x1.item(), y1.item(), x2.item(), y2.item()],\n",
    "            'confidence': confidence.item(),\n",
    "            'class_id': class_id\n",
    "        })\n",
    "\n",
    "# Convert to JSON\n",
    "json_output = json.dumps(detections, indent=4)\n",
    "\n",
    "# Save to a file or print it\n",
    "with open('output.json', 'w') as json_file:\n",
    "    json_file.write(json_output)\n",
    "\n",
    "print(json_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Results' object has no attribute 'pred'. See valid attributes below.\n\n    A class for storing and manipulating inference results.\n\n    This class encapsulates the functionality for handling detection, segmentation, pose estimation,\n    and classification results from YOLO models.\n\n    Attributes:\n        orig_img (numpy.ndarray): Original image as a numpy array.\n        orig_shape (Tuple[int, int]): Original image shape in (height, width) format.\n        boxes (Boxes | None): Object containing detection bounding boxes.\n        masks (Masks | None): Object containing detection masks.\n        probs (Probs | None): Object containing class probabilities for classification tasks.\n        keypoints (Keypoints | None): Object containing detected keypoints for each object.\n        obb (OBB | None): Object containing oriented bounding boxes.\n        speed (Dict[str, float | None]): Dictionary of preprocess, inference, and postprocess speeds.\n        names (Dict[int, str]): Dictionary mapping class IDs to class names.\n        path (str): Path to the image file.\n        _keys (Tuple[str, ...]): Tuple of attribute names for internal use.\n\n    Methods:\n        update: Updates object attributes with new detection results.\n        cpu: Returns a copy of the Results object with all tensors on CPU memory.\n        numpy: Returns a copy of the Results object with all tensors as numpy arrays.\n        cuda: Returns a copy of the Results object with all tensors on GPU memory.\n        to: Returns a copy of the Results object with tensors on a specified device and dtype.\n        new: Returns a new Results object with the same image, path, and names.\n        plot: Plots detection results on an input image, returning an annotated image.\n        show: Shows annotated results on screen.\n        save: Saves annotated results to file.\n        verbose: Returns a log string for each task, detailing detections and classifications.\n        save_txt: Saves detection results to a text file.\n        save_crop: Saves cropped detection images.\n        tojson: Converts detection results to JSON format.\n\n    Examples:\n        >>> results = model(\"path/to/image.jpg\")\n        >>> for result in results:\n        ...     print(result.boxes)  # Print detection boxes\n        ...     result.show()  # Display the annotated image\n        ...     result.save(filename=\"result.jpg\")  # Save annotated image\n    ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Iterate over the results to extract relevant information\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[0;32m----> 6\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpred\u001b[49m[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Assuming predictions are in the first element\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m prediction \u001b[38;5;129;01min\u001b[39;00m predictions:\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;66;03m# Extracting the relevant fields: box coordinates, confidence, class id\u001b[39;00m\n\u001b[1;32m      9\u001b[0m         output_data\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     10\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mint\u001b[39m(prediction[\u001b[38;5;241m5\u001b[39m]),  \u001b[38;5;66;03m# Assuming class id is at index 5\u001b[39;00m\n\u001b[1;32m     11\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfidence\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(prediction[\u001b[38;5;241m4\u001b[39m]),  \u001b[38;5;66;03m# Confidence at index 4\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m             }\n\u001b[1;32m     18\u001b[0m         })\n",
      "File \u001b[0;32m~/Environments/yolo/lib/python3.10/site-packages/ultralytics/utils/__init__.py:219\u001b[0m, in \u001b[0;36mSimpleClass.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Custom attribute access error message with helpful information.\"\"\"\u001b[39;00m\n\u001b[1;32m    218\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m--> 219\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. See valid attributes below.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Results' object has no attribute 'pred'. See valid attributes below.\n\n    A class for storing and manipulating inference results.\n\n    This class encapsulates the functionality for handling detection, segmentation, pose estimation,\n    and classification results from YOLO models.\n\n    Attributes:\n        orig_img (numpy.ndarray): Original image as a numpy array.\n        orig_shape (Tuple[int, int]): Original image shape in (height, width) format.\n        boxes (Boxes | None): Object containing detection bounding boxes.\n        masks (Masks | None): Object containing detection masks.\n        probs (Probs | None): Object containing class probabilities for classification tasks.\n        keypoints (Keypoints | None): Object containing detected keypoints for each object.\n        obb (OBB | None): Object containing oriented bounding boxes.\n        speed (Dict[str, float | None]): Dictionary of preprocess, inference, and postprocess speeds.\n        names (Dict[int, str]): Dictionary mapping class IDs to class names.\n        path (str): Path to the image file.\n        _keys (Tuple[str, ...]): Tuple of attribute names for internal use.\n\n    Methods:\n        update: Updates object attributes with new detection results.\n        cpu: Returns a copy of the Results object with all tensors on CPU memory.\n        numpy: Returns a copy of the Results object with all tensors as numpy arrays.\n        cuda: Returns a copy of the Results object with all tensors on GPU memory.\n        to: Returns a copy of the Results object with tensors on a specified device and dtype.\n        new: Returns a new Results object with the same image, path, and names.\n        plot: Plots detection results on an input image, returning an annotated image.\n        show: Shows annotated results on screen.\n        save: Saves annotated results to file.\n        verbose: Returns a log string for each task, detailing detections and classifications.\n        save_txt: Saves detection results to a text file.\n        save_crop: Saves cropped detection images.\n        tojson: Converts detection results to JSON format.\n\n    Examples:\n        >>> results = model(\"path/to/image.jpg\")\n        >>> for result in results:\n        ...     print(result.boxes)  # Print detection boxes\n        ...     result.show()  # Display the annotated image\n        ...     result.save(filename=\"result.jpg\")  # Save annotated image\n    "
     ]
    }
   ],
   "source": [
    "\n",
    "# Prepare the JSON output\n",
    "output_data = []\n",
    "\n",
    "# Iterate over the results to extract relevant information\n",
    "for result in results:\n",
    "    predictions = result.pred[0]  # Assuming predictions are in the first element\n",
    "    for prediction in predictions:\n",
    "        # Extracting the relevant fields: box coordinates, confidence, class id\n",
    "        output_data.append({\n",
    "            \"class_id\": int(prediction[5]),  # Assuming class id is at index 5\n",
    "            \"confidence\": float(prediction[4]),  # Confidence at index 4\n",
    "            \"box\": {\n",
    "                \"x1\": float(prediction[0]),  # x1 coordinate\n",
    "                \"y1\": float(prediction[1]),  # y1 coordinate\n",
    "                \"x2\": float(prediction[2]),  # x2 coordinate\n",
    "                \"y2\": float(prediction[3])   # y2 coordinate\n",
    "            }\n",
    "        })\n",
    "\n",
    "# Save the output as a JSON file\n",
    "with open('predictions.json', 'w') as json_file:\n",
    "    json.dump(output_data, json_file, indent=4)\n",
    "\n",
    "print(\"Predictions saved to predictions.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/Sem5/DL/DL-Project/Code/Guru/merge/images/NEFT.jpg: 1216x896 18 boxInputs, 9 lineInputs, 3 signatures, 75.0ms\n",
      "Speed: 10.8ms preprocess, 75.0ms inference, 10.8ms postprocess per image at shape (1, 3, 1216, 896)\n",
      "\n",
      "image 1/1 /mnt/d/Sem5/DL/DL-Project/Code/Guru/merge/images/NEFT.jpg: 1216x896 15 boxInputs, 18 lineInputs, 1 signature, 44.2ms\n",
      "Speed: 9.4ms preprocess, 44.2ms inference, 4.1ms postprocess per image at shape (1, 3, 1216, 896)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load both models\n",
    "model_a = YOLO('./models/best-071024-2.pt')\n",
    "model_b = YOLO('./models/best-071024-3.pt')\n",
    "\n",
    "# Run inference on the same image\n",
    "image_path = './images/NEFT.jpg'\n",
    "results_a = model_a(image_path)\n",
    "results_b = model_b(image_path)\n",
    "\n",
    "# Function to extract detections\n",
    "def extract_detections(results):\n",
    "    detections = []\n",
    "    for result in results:\n",
    "        for detection in result.boxes:\n",
    "            x1, y1, x2, y2 = detection.xyxy[0]\n",
    "            confidence = detection.conf[0]\n",
    "            class_id = int(detection.cls[0])\n",
    "            detections.append({\n",
    "                'bbox': [x1.item(), y1.item(), x2.item(), y2.item()],\n",
    "                'confidence': confidence.item(),\n",
    "                'class_id': class_id\n",
    "            })\n",
    "    return detections\n",
    "\n",
    "# Extract detections\n",
    "detections_a = extract_detections(results_a)\n",
    "detections_b = extract_detections(results_b)\n",
    "\n",
    "# Combine detections\n",
    "def combine_detections(detections_a, detections_b, iou_threshold=0.5):\n",
    "    combined = []\n",
    "    def iou(box1, box2):\n",
    "        x1_inter = max(box1[0], box2[0])\n",
    "        y1_inter = max(box1[1], box2[1])\n",
    "        x2_inter = min(box1[2], box2[2])\n",
    "        y2_inter = min(box1[3], box2[3])\n",
    "        \n",
    "        inter_area = max(0, x2_inter - x1_inter) * max(0, y2_inter - y1_inter)\n",
    "        box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "        box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "        \n",
    "        return inter_area / (box1_area + box2_area - inter_area)\n",
    "\n",
    "    for detection in detections_a:\n",
    "        combined.append(detection)\n",
    "\n",
    "    for detection_b in detections_b:\n",
    "        is_conflicted = False\n",
    "        for detection_a in combined:\n",
    "            if iou(detection_a['bbox'], detection_b['bbox']) > iou_threshold:\n",
    "                is_conflicted = True\n",
    "                if detection_b['confidence'] > detection_a['confidence']:\n",
    "                    combined.remove(detection_a)\n",
    "                    combined.append(detection_b)\n",
    "                break\n",
    "        if not is_conflicted:\n",
    "            combined.append(detection_b)\n",
    "\n",
    "    return combined\n",
    "\n",
    "final_detections = combine_detections(detections_a, detections_b)\n",
    "\n",
    "# Load the original image\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Function to draw detections\n",
    "def draw_detections(image, detections):\n",
    "    for detection in detections:\n",
    "        bbox = detection['bbox']\n",
    "        confidence = detection['confidence']\n",
    "        class_id = detection['class_id']\n",
    "        \n",
    "        x1, y1, x2, y2 = map(int, bbox)\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        label = f'Class {class_id}: {confidence:.2f}'\n",
    "        cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "draw_detections(image, final_detections)\n",
    "\n",
    "# Save the output image\n",
    "output_image_path = 'output_image.jpg'\n",
    "cv2.imwrite(output_image_path, image)\n",
    "\n",
    "# Display the image (optional)\n",
    "# cv2.imshow(\"Detections\", image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/Sem5/DL/DL-Project/Code/Guru/merge/images/NEFT.jpg: 1216x896 18 boxInputs, 9 lineInputs, 3 signatures, 79.0ms\n",
      "Speed: 11.8ms preprocess, 79.0ms inference, 11.4ms postprocess per image at shape (1, 3, 1216, 896)\n",
      "\n",
      "image 1/1 /mnt/d/Sem5/DL/DL-Project/Code/Guru/merge/images/NEFT.jpg: 1216x896 15 boxInputs, 18 lineInputs, 1 signature, 40.7ms\n",
      "Speed: 8.2ms preprocess, 40.7ms inference, 2.8ms postprocess per image at shape (1, 3, 1216, 896)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load both models\n",
    "model_a = YOLO('./models/best-071024-2.pt')\n",
    "model_b = YOLO('./models/best-071024-3.pt')\n",
    "\n",
    "# Run inference on the same image\n",
    "image_path = './images/NEFT.jpg'\n",
    "results_a = model_a(image_path)\n",
    "results_b = model_b(image_path)\n",
    "\n",
    "# Extract detections\n",
    "def extract_detections(results):\n",
    "    detections = []\n",
    "    for result in results:\n",
    "        for detection in result.boxes:\n",
    "            x1, y1, x2, y2 = detection.xyxy[0]\n",
    "            confidence = detection.conf[0]\n",
    "            class_id = int(detection.cls[0])\n",
    "            detections.append({\n",
    "                'bbox': [x1.item(), y1.item(), x2.item(), y2.item()],\n",
    "                'confidence': confidence.item(),\n",
    "                'class_id': class_id\n",
    "            })\n",
    "    return detections\n",
    "\n",
    "\n",
    "# Filter nested detections\n",
    "def filter_nested_detections(detections):\n",
    "    filtered_detections = []\n",
    "    for det in detections:\n",
    "        x1, y1, x2, y2 = det['bbox']\n",
    "        is_nested = False\n",
    "        for other_det in detections:\n",
    "            if det != other_det:\n",
    "                ox1, oy1, ox2, oy2 = other_det['bbox']\n",
    "                if x1 >= ox1 and y1 >= oy1 and x2 <= ox2 and y2 <= oy2:\n",
    "                    is_nested = True\n",
    "                    break\n",
    "        if not is_nested:\n",
    "            filtered_detections.append(det)\n",
    "    return filtered_detections\n",
    "\n",
    "# Extract and filter detections from both models\n",
    "detections_a = filter_nested_detections(extract_detections(results_a))\n",
    "detections_b = filter_nested_detections(extract_detections(results_b))\n",
    "# Create cost matrix\n",
    "def create_cost_matrix(detections_a, detections_b):\n",
    "    cost_matrix = np.zeros((len(detections_a), len(detections_b)))\n",
    "    \n",
    "    for i, det_a in enumerate(detections_a):\n",
    "        for j, det_b in enumerate(detections_b):\n",
    "            # Here you can use distance or other criteria for the cost function\n",
    "            cost_matrix[i, j] = 1 - min(det_a['confidence'], det_b['confidence'])  # Example cost function\n",
    "            \n",
    "    return cost_matrix\n",
    "\n",
    "# Perform matching using Hungarian Algorithm\n",
    "def hungarian_matching(cost_matrix):\n",
    "    row_indices, col_indices = linear_sum_assignment(cost_matrix)\n",
    "    return list(zip(row_indices, col_indices))\n",
    "\n",
    "# Create cost matrix\n",
    "cost_matrix = create_cost_matrix(detections_a, detections_b)\n",
    "\n",
    "# Perform matching\n",
    "matches = hungarian_matching(cost_matrix)\n",
    "\n",
    "# Load the original image\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Draw matches\n",
    "def draw_matches(image, detections_a, detections_b, matches):\n",
    "    for i, j in matches:\n",
    "        bbox_a = detections_a[i]['bbox']\n",
    "        bbox_b = detections_b[j]['bbox']\n",
    "        \n",
    "        # Draw bounding box for model A\n",
    "        x1_a, y1_a, x2_a, y2_a = map(int, bbox_a)\n",
    "        cv2.rectangle(image, (x1_a, y1_a), (x2_a, y2_a), (0, 255, 0), 2)  # Green box\n",
    "        \n",
    "        # Draw bounding box for model B\n",
    "        x1_b, y1_b, x2_b, y2_b = map(int, bbox_b)\n",
    "        cv2.rectangle(image, (x1_b, y1_b), (x2_b, y2_b), (255, 0, 0), 2)  # Blue box\n",
    "        \n",
    "        # Label with class id and confidence\n",
    "        label_a = f'A: {detections_a[i][\"class_id\"]} {detections_a[i][\"confidence\"]:.2f}'\n",
    "        label_b = f'B: {detections_b[j][\"class_id\"]} {detections_b[j][\"confidence\"]:.2f}'\n",
    "        \n",
    "        cv2.putText(image, label_a, (x1_a, y1_a - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        cv2.putText(image, label_b, (x1_b, y1_b - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "# Draw the matches on the image\n",
    "draw_matches(image, detections_a, detections_b, matches)\n",
    "\n",
    "# Save or display the image\n",
    "output_image_path = 'output_image.jpg'\n",
    "cv2.imwrite(output_image_path, image)\n",
    "# cv2.imshow(\"Matches\", image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/d/Sem5/DL/DL-Project/Code/Guru/merge/images/NEFT.jpg: 1216x896 18 boxInputs, 9 lineInputs, 3 signatures, 32.9ms\n",
      "Speed: 6.8ms preprocess, 32.9ms inference, 3.1ms postprocess per image at shape (1, 3, 1216, 896)\n",
      "\n",
      "image 1/1 /mnt/d/Sem5/DL/DL-Project/Code/Guru/merge/images/NEFT.jpg: 1216x896 15 boxInputs, 18 lineInputs, 1 signature, 33.9ms\n",
      "Speed: 9.0ms preprocess, 33.9ms inference, 1.8ms postprocess per image at shape (1, 3, 1216, 896)\n",
      "Detection 1: Class 6, Confidence: 0.99\n",
      "Detection 2: Class 5, Confidence: 0.98\n",
      "Detection 3: Class 6, Confidence: 0.97\n",
      "Detection 4: Class 3, Confidence: 0.98\n",
      "Detection 5: Class 3, Confidence: 0.98\n",
      "Detection 6: Class 5, Confidence: 0.96\n",
      "Detection 7: Class 3, Confidence: 0.96\n",
      "Detection 8: Class 3, Confidence: 0.95\n",
      "Detection 9: Class 6, Confidence: 0.94\n",
      "Detection 10: Class 3, Confidence: 0.93\n",
      "Detection 11: Class 5, Confidence: 0.92\n",
      "Detection 12: Class 3, Confidence: 0.93\n",
      "Detection 13: Class 3, Confidence: 0.93\n",
      "Detection 14: Class 3, Confidence: 0.86\n",
      "Detection 15: Class 3, Confidence: 0.90\n",
      "Detection 16: Class 5, Confidence: 0.85\n",
      "Detection 17: Class 3, Confidence: 0.86\n",
      "Detection 18: Class 5, Confidence: 0.96\n",
      "Detection 19: Class 3, Confidence: 0.93\n",
      "Detection 20: Class 3, Confidence: 0.90\n",
      "Detection 21: Class 3, Confidence: 0.63\n",
      "Detection 22: Class 5, Confidence: 0.56\n",
      "Detection 23: Class 3, Confidence: 0.50\n",
      "Detection 24: Class 5, Confidence: 0.45\n",
      "Detection 25: Class 5, Confidence: 0.91\n",
      "Detection 26: Class 5, Confidence: 0.28\n",
      "Detection 27: Class 5, Confidence: 0.71\n",
      "Detection 28: Class 5, Confidence: 0.65\n",
      "Detection 29: Class 6, Confidence: 0.50\n",
      "Detection 30: Class 5, Confidence: 0.47\n",
      "Detection 31: Class 5, Confidence: 0.47\n",
      "Detection 32: Class 5, Confidence: 0.35\n",
      "Detection 33: Class 5, Confidence: 0.34\n",
      "Detection 34: Class 5, Confidence: 0.32\n",
      "Detection 35: Class 5, Confidence: 0.30\n",
      "Detection 36: Class 5, Confidence: 0.27\n",
      "Detection 37: Class 5, Confidence: 0.26\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from shapely.geometry import box\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "# Load models\n",
    "model_a = YOLO('./models/best-071024-2.pt')\n",
    "model_b = YOLO('./models/best-071024-3.pt')\n",
    "\n",
    "def extract_detections(results):\n",
    "    detections = []\n",
    "    for result in results:\n",
    "        for detection in result.boxes:\n",
    "            x1, y1, x2, y2 = detection.xyxy[0]\n",
    "            confidence = detection.conf[0]\n",
    "            class_id = int(detection.cls[0])\n",
    "            detections.append({\n",
    "                'bbox': [x1.item(), y1.item(), x2.item(), y2.item()],\n",
    "                'confidence': confidence.item(),\n",
    "                'class_id': class_id\n",
    "            })\n",
    "    return detections\n",
    "\n",
    "def calculate_iou(box1, box2):\n",
    "    # Convert to shapely boxes\n",
    "    box1_shape = box(box1[0], box1[1], box1[2], box1[3])\n",
    "    box2_shape = box(box2[0], box2[1], box2[2], box2[3])\n",
    "    \n",
    "    if not box1_shape.intersects(box2_shape):\n",
    "        return 0\n",
    "    \n",
    "    intersection = box1_shape.intersection(box2_shape).area\n",
    "    union = box1_shape.union(box2_shape).area\n",
    "    \n",
    "    return intersection / union\n",
    "\n",
    "def merge_boxes(box1, box2):\n",
    "    # Convert to shapely boxes\n",
    "    box1_shape = box(box1[0], box1[1], box1[2], box1[3])\n",
    "    box2_shape = box(box2[0], box2[1], box2[2], box2[3])\n",
    "    \n",
    "    # Merge boxes\n",
    "    merged_box = unary_union([box1_shape, box2_shape])\n",
    "    bounds = merged_box.bounds\n",
    "    \n",
    "    return list(bounds)\n",
    "\n",
    "def group_detections(detections_a, detections_b, iou_threshold=0.5):\n",
    "    all_detections = detections_a + detections_b\n",
    "    grouped_detections = []\n",
    "    processed = set()\n",
    "\n",
    "    for i, det1 in enumerate(all_detections):\n",
    "        if i in processed:\n",
    "            continue\n",
    "\n",
    "        current_group = [det1]\n",
    "        processed.add(i)\n",
    "\n",
    "        for j, det2 in enumerate(all_detections):\n",
    "            if j in processed or i == j:\n",
    "                continue\n",
    "\n",
    "            if (det1['class_id'] == det2['class_id'] and \n",
    "                calculate_iou(det1['bbox'], det2['bbox']) > iou_threshold):\n",
    "                current_group.append(det2)\n",
    "                processed.add(j)\n",
    "\n",
    "        if len(current_group) > 1:\n",
    "            # Merge all boxes in the group\n",
    "            merged_bbox = current_group[0]['bbox']\n",
    "            max_conf = current_group[0]['confidence']\n",
    "            \n",
    "            for det in current_group[1:]:\n",
    "                merged_bbox = merge_boxes(merged_bbox, det['bbox'])\n",
    "                max_conf = max(max_conf, det['confidence'])\n",
    "\n",
    "            grouped_detections.append({\n",
    "                'bbox': merged_bbox,\n",
    "                'confidence': max_conf,\n",
    "                'class_id': current_group[0]['class_id']\n",
    "            })\n",
    "        else:\n",
    "            grouped_detections.append(current_group[0])\n",
    "\n",
    "    return grouped_detections\n",
    "\n",
    "def draw_detections(image, detections):\n",
    "    colors = [(0, 255, 0), (255, 0, 0), (0, 0, 255)]  # Green, Blue, Red\n",
    "    \n",
    "    for i, det in enumerate(detections):\n",
    "        x1, y1, x2, y2 = map(int, det['bbox'])\n",
    "        color = colors[i % len(colors)]\n",
    "        \n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
    "        label = f\"Class {det['class_id']} ({det['confidence']:.2f})\"\n",
    "        cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "def process_image(image_path):\n",
    "    # Run inference\n",
    "    results_a = model_a(image_path)\n",
    "    results_b = model_b(image_path)\n",
    "    \n",
    "    # Extract detections\n",
    "    detections_a = extract_detections(results_a)\n",
    "    detections_b = extract_detections(results_b)\n",
    "    \n",
    "    # Group and merge detections\n",
    "    final_detections = group_detections(detections_a, detections_b)\n",
    "    \n",
    "    # Draw results\n",
    "    image = cv2.imread(image_path)\n",
    "    draw_detections(image, final_detections)\n",
    "    \n",
    "    return image, final_detections\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    image_path = './images/NEFT.jpg'\n",
    "    output_image, final_detections = process_image(image_path)\n",
    "    \n",
    "    # Save the output image\n",
    "    cv2.imwrite('output_merged_detections.jpg', output_image)\n",
    "    \n",
    "    # Print detection results\n",
    "    for i, det in enumerate(final_detections):\n",
    "        print(f\"Detection {i+1}: Class {det['class_id']}, Confidence: {det['confidence']:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
